# -*- coding: utf-8 -*-
"""AnalisisPaper2Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_ZVxiQrZ4wd3MoTDgR7bq34wehY7lUaH
"""

#Instalar y configurar Kaggle API en Colab

# Instala la API de Kaggle (si aún no está instalada)
!pip install -q kaggle

# Sube tu archivo kaggle.json
from google.colab import files
files.upload()  # Selecciona el archivo kaggle.json

# Mueve el archivo a la carpeta correcta y da permisos
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

import kagglehub

# Download latest version
path = kagglehub.dataset_download("pcbreviglieri/pneumonia-xray-images")

print("Path to dataset files:", path)

import os

# Muestra la estructura principal del dataset
print("Contenido del dataset raíz:", os.listdir(path))

# Muestra el contenido de train, val y test
for subfolder in ['train', 'val', 'test']:
    folder_path = os.path.join(path, subfolder)
    print(f"\nContenido de '{subfolder}':", os.listdir(folder_path))
    if subfolder != 'test':  # test probablemente solo tiene imágenes sueltas
        for clase in os.listdir(folder_path):
            clase_path = os.path.join(folder_path, clase)
            print(f"  - {subfolder}/{clase}: {len(os.listdir(clase_path))} imágenes")

from tensorflow.keras.preprocessing.image import ImageDataGenerator

IMG_SIZE = 100
BATCH_SIZE = 32

train_dir = os.path.join(path, 'train')
val_dir   = os.path.join(path, 'val')
test_dir  = os.path.join(path, 'test')

datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    zoom_range=0.2,
    shear_range=0.1,
    horizontal_flip=True,
    fill_mode='nearest'
)

train_generator = datagen.flow_from_directory(
    train_dir,
    target_size=(IMG_SIZE, IMG_SIZE),
    color_mode='grayscale',
    batch_size=BATCH_SIZE,
    class_mode='binary'
)

val_generator = datagen.flow_from_directory(
    val_dir,
    target_size=(IMG_SIZE, IMG_SIZE),
    color_mode='grayscale',
    batch_size=BATCH_SIZE,
    class_mode='binary'
)

import matplotlib.pyplot as plt

x_batch, y_batch = next(train_generator)
plt.figure(figsize=(12, 5))
for i in range(10):
    plt.subplot(2, 5, i+1)
    plt.imshow(x_batch[i].reshape(IMG_SIZE, IMG_SIZE), cmap='gray')
    plt.title('Neumonía' if y_batch[i] else 'Normal')
    plt.axis('off')
plt.tight_layout()
plt.show()

from tensorflow.keras import layers, models

model = models.Sequential([
    layers.Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)),
    layers.MaxPooling2D(2,2),
    layers.Conv2D(64, (3,3), activation='relu'),
    layers.MaxPooling2D(2,2),
    layers.Conv2D(128, (3,3), activation='relu'),
    layers.MaxPooling2D(2,2),
    layers.Dropout(0.4),
    layers.Flatten(),
    layers.Dense(100, activation='relu'),
    layers.Dropout(0.3),
    layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.summary()

from tensorflow.keras.callbacks import EarlyStopping

early_stop = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)

history = model.fit(
    train_generator,
    epochs=40,
    validation_data=val_generator,
    callbacks=[early_stop]
)

import os

print("Archivos en test_dir:", os.listdir(test_dir))

import glob
import cv2
import numpy as np

val_normal = os.path.join(val_dir, 'normal')
val_opacity = os.path.join(val_dir, 'opacity')

val_files_normal = glob.glob(os.path.join(val_normal, "*.jpeg")) + \
                   glob.glob(os.path.join(val_normal, "*.jpg")) + \
                   glob.glob(os.path.join(val_normal, "*.png"))

val_files_opacity = glob.glob(os.path.join(val_opacity, "*.jpeg")) + \
                    glob.glob(os.path.join(val_opacity, "*.jpg")) + \
                    glob.glob(os.path.join(val_opacity, "*.png"))

val_files = val_files_normal + val_files_opacity
y_val = [0]*len(val_files_normal) + [1]*len(val_files_opacity)

print(f"Número de imágenes en validación: {len(val_files)}")

X_val_eval = []
for fname in val_files:
    img = cv2.imread(fname, cv2.IMREAD_GRAYSCALE)
    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))
    img = img.astype(np.float32) / 255.0
    X_val_eval.append(img)

X_val_eval = np.array(X_val_eval).reshape(-1, IMG_SIZE, IMG_SIZE, 1)
y_val = np.array(y_val)

y_pred_proba = model.predict(X_val_eval)
y_pred = (y_pred_proba > 0.5).astype(int).flatten()

from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

print(classification_report(y_val, y_pred, target_names=['Normal', 'Neumonía']))

plt.figure(figsize=(5, 4))
sns.heatmap(confusion_matrix(y_val, y_pred), annot=True, fmt='d', cmap='Blues',
            xticklabels=['Normal', 'Neumonía'], yticklabels=['Normal', 'Neumonía'])
plt.ylabel('Real')
plt.xlabel('Predicho')
plt.title('Matriz de confusión')
plt.show()

plt.figure(figsize=(15, 8))
for i in range(min(15, len(X_val_eval))):
    pred = 'Neumonía' if y_pred[i] else 'Normal'
    real = 'Neumonía' if y_val[i] else 'Normal'
    plt.subplot(3, 5, i+1)
    plt.imshow(X_val_eval[i].reshape(IMG_SIZE, IMG_SIZE), cmap='gray')
    plt.title(f"P:{pred}\nR:{real}", fontsize=10)
    plt.axis('off')
plt.tight_layout()
plt.show()

model.export("modelo_terminado")

# Conversión a TensorFlow.js
!pip install tensorflowjs

!mkdir caperta_salida

!tensorflowjs_converter \
  --input_format=tf_saved_model \
  --output_format=tfjs_graph_model \
  modelo_terminado caperta_salida